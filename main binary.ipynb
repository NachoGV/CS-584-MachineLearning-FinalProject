{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom\n",
    "from utils.dataset_manager import fit_dataset, get_classes_weights\n",
    "from utils.constant import ALL_ATTACKS, FEATURES, LABELS\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "# Other\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from joblib import dump\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Population: 522642\n",
      "Testing Population: 182230\n"
     ]
    }
   ],
   "source": [
    "n_files = 20\n",
    "\n",
    "df_train, df_test = fit_dataset(n_files, ALL_ATTACKS, dataset_directory='./data/')\n",
    "\n",
    "# Binary classification: Bening traffic vs. DDoS traffic\n",
    "df_train = df_train[(df_train[LABELS] == ALL_ATTACKS['DDoS-SYN_Flood']) | (df_train[LABELS] == ALL_ATTACKS['BenignTraffic'])]\n",
    "df_test = df_test[(df_test[LABELS] == ALL_ATTACKS['DDoS-SYN_Flood']) | (df_test[LABELS] == ALL_ATTACKS['BenignTraffic'])]\n",
    "\n",
    "df_train[LABELS] = df_train[LABELS].apply(lambda x: 1 if x == ALL_ATTACKS['DDoS-SYN_Flood'] else 0)\n",
    "df_test[LABELS] = df_test[LABELS].apply(lambda x: 1 if x == ALL_ATTACKS['DDoS-SYN_Flood'] else 0)\n",
    "\n",
    "X_train, y_train = df_train[FEATURES], df_train[LABELS]\n",
    "X_test, y_test = df_test[FEATURES], df_test[LABELS]\n",
    "\n",
    "# Prints\n",
    "print('Training Population: {}'.format(len(df_train)))\n",
    "print('Testing Population: {}'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have unbalanced data, we have to add their weigth in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"min_samples_leaf\": [1, 3, 5],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"class_weight\": [\"balanced\", get_classes_weights(df_train)],\n",
    "}\n",
    "\n",
    "log_reg_params = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.1, 0.5, 1, 5, 10],\n",
    "    \"class_weight\": [\"balanced\", get_classes_weights(df_train)],\n",
    "}\n",
    "\n",
    "voting_params = {\n",
    "    \"voting\": [\"soft\", \"hard\"],\n",
    "    \"weights\": [[1, 1, 1], [1, 2, 1], [1, 1, 2], [1, 2, 2]],\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'log_reg': (LogisticRegression(class_weight=get_classes_weights(df_train)), log_reg_params),\n",
    "    'xgb': (XGBClassifier(), xgb_params),\n",
    "    'random_forest': (RandomForestClassifier(class_weight=get_classes_weights(df_train)), rf_params),\n",
    "    'voting_classifier': (VotingClassifier(estimators=[('xgb', XGBClassifier()), ('rf', RandomForestClassifier()), ('logistic', LogisticRegression())], voting='soft'), voting_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:20<04:02, 80.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Best score: 0.9984350042428976\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [25:54<29:59, 899.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'reg_lambda': 0, 'scale_pos_weight': 1, 'subsample': 0.8}\n",
      "Best score: 0.9999942887426471\n",
      "Training random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [1:16:38<31:19, 1879.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "Best score: 0.9985745085665645\n",
      "Training voting_classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:22:59<00:00, 1244.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'voting': 'hard', 'weights': [1, 2, 1]}\n",
      "Best score: 0.9999971444181665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_estimators = {}\n",
    "for model in tqdm(models):\n",
    "    print('Training {}'.format(model))\n",
    "    grid = GridSearchCV(models[model][0], models[model][1], cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print('Best params: {}'.format(grid.best_params_))\n",
    "    print('Best score: {}'.format(grid.best_score_))\n",
    "    best_estimators[model] = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_reg': LogisticRegression(C=0.1, class_weight='balanced'),\n",
       " 'xgb': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=0, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       " 'random_forest': RandomForestClassifier(class_weight='balanced', max_depth=7, n_estimators=200),\n",
       " 'voting_classifier': VotingClassifier(estimators=[('xgb',\n",
       "                               XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             learning_ra...max_bin=None,\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None, max_depth=None,\n",
       "                                             max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...)),\n",
       "                              ('rf', RandomForestClassifier()),\n",
       "                              ('logistic', LogisticRegression())],\n",
       "                  weights=[1, 2, 1])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  log_reg\n",
      "  accuracy_score =  0.9991329638369094\n",
      "  recall_score =  0.9979859744863098\n",
      "  precision_score =  0.9994306917404566\n",
      "  f1_score =  0.9987062225107972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     38863\n",
      "           1       1.00      1.00      1.00    143367\n",
      "\n",
      "    accuracy                           1.00    182230\n",
      "   macro avg       1.00      1.00      1.00    182230\n",
      "weighted avg       1.00      1.00      1.00    182230\n",
      "\n",
      "Model:  xgb\n",
      "  accuracy_score =  0.9999945124293476\n",
      "  recall_score =  0.9999965162135422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:01<00:01,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  precision_score =  0.9999870831072877\n",
      "  f1_score =  0.9999917995709224\n",
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     38708\n",
      "           1       1.00      1.00      1.00    143522\n",
      "\n",
      "    accuracy                           1.00    182230\n",
      "   macro avg       1.00      1.00      1.00    182230\n",
      "weighted avg       1.00      1.00      1.00    182230\n",
      "\n",
      "Model:  random_forest\n",
      "  accuracy_score =  0.9991933271140866\n",
      "  recall_score =  0.9981176842313443\n",
      "  precision_score =  0.9994784467404842\n",
      "  f1_score =  0.9987961937204097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     38854\n",
      "           1       1.00      1.00      1.00    143376\n",
      "\n",
      "    accuracy                           1.00    182230\n",
      "   macro avg       1.00      1.00      1.00    182230\n",
      "weighted avg       1.00      1.00      1.00    182230\n",
      "\n",
      "Model:  voting_classifier\n",
      "  accuracy_score =  0.999989024858695\n",
      "  recall_score =  0.9999835992965562\n",
      "  precision_score =  0.9999835992965562\n",
      "  f1_score =  0.9999835992965562\n",
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     38709\n",
      "           1       1.00      1.00      1.00    143521\n",
      "\n",
      "    accuracy                           1.00    182230\n",
      "   macro avg       1.00      1.00      1.00    182230\n",
      "weighted avg       1.00      1.00      1.00    182230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./outputs/best_model_syn_attacks.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for model in tqdm(best_estimators):\n",
    "    y_pred = list(best_estimators[model].predict(X_test))\n",
    "\n",
    "    # Evaluate\n",
    "    y_test = list(y_test)\n",
    "    f1score = f1_score(y_pred, y_test, average='macro')\n",
    "    print('Model: ', model)\n",
    "    print('  accuracy_score = ', accuracy_score(y_pred, y_test))\n",
    "    print('  recall_score = ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('  precision_score = ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('  f1_score = ', f1score)\n",
    "    print('  classification_report = \\n', classification_report(y_pred, y_test))\n",
    "\n",
    "    if f1score > best_score:\n",
    "        best_score = f1score\n",
    "        best_model = best_estimators[model]\n",
    "\n",
    "dump(best_model, './outputs/best_model_syn_attacks.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
