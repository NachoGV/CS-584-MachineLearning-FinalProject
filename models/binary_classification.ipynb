{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.dataset_manager import fit_dataset, get_classes_weights\n",
    "from utils.constant import ATTACKS, ALL_ATTACKS, FEATURES, LABELS\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "# Other\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.47s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Population: 50774\n",
      "Testing Population: 30550\n"
     ]
    }
   ],
   "source": [
    "n_files = 2\n",
    "\n",
    "df_train, df_test = fit_dataset(n_files, ALL_ATTACKS)\n",
    "\n",
    "# Binary classification: Bening traffic vs. DDoS traffic\n",
    "df_train = df_train[(df_train[LABELS] == ALL_ATTACKS['DDoS-SYN_Flood']) | (df_train[LABELS] == ALL_ATTACKS['BenignTraffic'])]\n",
    "df_test = df_test[(df_test[LABELS] == ALL_ATTACKS['DDoS-SYN_Flood']) | (df_test[LABELS] == ALL_ATTACKS['BenignTraffic'])]\n",
    "\n",
    "df_train[LABELS] = df_train[LABELS].apply(lambda x: 1 if x == ALL_ATTACKS['DDoS-SYN_Flood'] else 0)\n",
    "df_test[LABELS] = df_test[LABELS].apply(lambda x: 1 if x == ALL_ATTACKS['DDoS-SYN_Flood'] else 0)\n",
    "\n",
    "X_train, y_train = df_train[FEATURES], df_train[LABELS]\n",
    "X_test, y_test = df_test[FEATURES], df_test[LABELS]\n",
    "\n",
    "# Prints\n",
    "print('Training Population: {}'.format(len(df_train)))\n",
    "print('Testing Population: {}'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.6350878070745984, 0: 2.350648148148148}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classes_weights(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have unbalanced data, we have to add their weigth in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'log_reg': LogisticRegression(class_weight=get_classes_weights(df_train)),\n",
    "    'xgb': XGBClassifier(scale_pos_weight=sum(y_train == 0) / sum(y_train == 1)),\n",
    "    #'svm': SVC(), # Too slow\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in tqdm(models):\n",
    "    models[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  log_reg\n",
      "  accuracy_score =  0.999050736497545\n",
      "  recall_score =  0.9979097813456863\n",
      "  precision_score =  0.9992271352927968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  f1_score =  0.9985667335407329\n",
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6410\n",
      "           1       1.00      1.00      1.00     24140\n",
      "\n",
      "    accuracy                           1.00     30550\n",
      "   macro avg       1.00      1.00      1.00     30550\n",
      "weighted avg       1.00      1.00      1.00     30550\n",
      "\n",
      "Model:  xgb\n",
      "  accuracy_score =  0.9998036006546644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  recall_score =  0.9995881286891597\n",
      "  precision_score =  0.9998182520117515\n",
      "  f1_score =  0.9997031379513762\n",
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6391\n",
      "           1       1.00      1.00      1.00     24159\n",
      "\n",
      "    accuracy                           1.00     30550\n",
      "   macro avg       1.00      1.00      1.00     30550\n",
      "weighted avg       1.00      1.00      1.00     30550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "for model in tqdm(models):\n",
    "    y_pred = list(models[model].predict(X_test))\n",
    "\n",
    "    # Evaluate\n",
    "    y_test = list(y_test)\n",
    "    print('Model: ', model)\n",
    "    print('  accuracy_score = ', accuracy_score(y_pred, y_test))\n",
    "    print('  recall_score = ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('  precision_score = ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('  f1_score = ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print('  classification_report = \\n', classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
