{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom\n",
    "from utils.dataset_manager import fit_dataset, get_classes_weights\n",
    "from utils.constant import ALL_ATTACKS, FEATURES, LABELS\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "# Other\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from joblib import dump\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.55s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Population: 457492\n",
      "Testing Population: 275258\n"
     ]
    }
   ],
   "source": [
    "n_files = 2\n",
    "\n",
    "df_train, df_test = fit_dataset(n_files, ALL_ATTACKS, dataset_directory='./data/')\n",
    "\n",
    "X_train, y_train = df_train[FEATURES], df_train[LABELS]\n",
    "X_test, y_test = df_test[FEATURES], df_test[LABELS]\n",
    "\n",
    "# Prints\n",
    "print('Training Population: {}'.format(len(df_train)))\n",
    "print('Testing Population: {}'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have unbalanced data, we have to add their weigth in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"min_samples_leaf\": [1, 3, 5],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"class_weight\": [\"balanced\", get_classes_weights(df_train)],\n",
    "}\n",
    "\n",
    "log_reg_params = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.1, 0.5, 1, 5, 10],\n",
    "    \"class_weight\": [\"balanced\", get_classes_weights(df_train)],\n",
    "}\n",
    "\n",
    "voting_params = {\n",
    "    \"voting\": [\"soft\", \"hard\"],\n",
    "    \"weights\": [[1, 1, 1], [1, 2, 1], [1, 1, 2], [1, 2, 2]],\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'log_reg': (LogisticRegression(class_weight=get_classes_weights(df_train)), log_reg_params),\n",
    "    'xgb': (XGBClassifier(), xgb_params),\n",
    "    'random_forest': (RandomForestClassifier(class_weight=get_classes_weights(df_train)), rf_params),\n",
    "    'voting_classifier': (VotingClassifier(estimators=[\n",
    "        ('xgb', XGBClassifier()),\n",
    "        ('rf', RandomForestClassifier(class_weight=get_classes_weights(df_train))),\n",
    "        ('logistic', LogisticRegression(class_weight=get_classes_weights(df_train)))],\n",
    "        voting='soft'), voting_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mdelucasg/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "  0%|          | 0/4 [04:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mdelucasg/dev/CS-584-FinalProject/main.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mdelucasg/dev/CS-584-FinalProject/main.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(model))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mdelucasg/dev/CS-584-FinalProject/main.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(models[model][\u001b[39m0\u001b[39m], models[model][\u001b[39m1\u001b[39m], cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mdelucasg/dev/CS-584-FinalProject/main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mdelucasg/dev/CS-584-FinalProject/main.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest params: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(grid\u001b[39m.\u001b[39mbest_params_))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mdelucasg/dev/CS-584-FinalProject/main.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest score: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(grid\u001b[39m.\u001b[39mbest_score_))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_estimators = {}\n",
    "for model in tqdm(models):\n",
    "    print('Training {}'.format(model))\n",
    "    grid = GridSearchCV(models[model][0], models[model][1], cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print('Best params: {}'.format(grid.best_params_))\n",
    "    print('Best score: {}'.format(grid.best_score_))\n",
    "    best_estimators[model] = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  log_reg\n",
      "  accuracy_score =  0.7741936655792021\n",
      "  recall_score =  0.48097141706008584\n",
      "  precision_score =  0.5256358749894402\n",
      "  f1_score =  0.473294530373888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23779\n",
      "           1       0.98      1.00      0.99     23474\n",
      "           2       0.93      0.66      0.77     34163\n",
      "           3       0.90      0.72      0.80     39454\n",
      "           4       0.79      0.65      0.71     32416\n",
      "           5       1.00      1.00      1.00     42280\n",
      "           6       0.63      0.77      0.69     17480\n",
      "           7       0.98      0.91      0.94      1758\n",
      "           8       0.98      0.92      0.95      1800\n",
      "           9       0.97      0.97      0.97      2680\n",
      "          10       0.51      0.15      0.23       459\n",
      "          11       0.69      0.26      0.37       396\n",
      "          12       0.44      0.74      0.55     11745\n",
      "          13       0.21      0.47      0.29      5279\n",
      "          14       0.27      0.43      0.33     10205\n",
      "          15       0.76      0.62      0.68       562\n",
      "          16       0.65      0.59      0.62      6261\n",
      "          17       0.41      0.49      0.45      3834\n",
      "          18       0.99      0.99      0.99      5225\n",
      "          19       0.10      0.00      0.00       548\n",
      "          20       0.06      0.13      0.08       261\n",
      "          21       0.06      0.06      0.06       523\n",
      "          22       0.56      0.17      0.26       700\n",
      "          23       0.53      0.64      0.58       678\n",
      "          24       0.22      0.27      0.24       865\n",
      "          25       0.50      0.70      0.59      1322\n",
      "          26       0.56      0.90      0.69      3957\n",
      "          27       0.22      0.01      0.02       732\n",
      "          28       0.08      0.00      0.00       463\n",
      "          29       0.27      0.01      0.02       489\n",
      "          30       0.00      0.00      0.00       579\n",
      "          31       0.14      0.01      0.02       453\n",
      "          32       0.24      0.03      0.05       221\n",
      "          33       0.24      0.10      0.14       217\n",
      "\n",
      "    accuracy                           0.77    275258\n",
      "   macro avg       0.53      0.48      0.47    275258\n",
      "weighted avg       0.82      0.77      0.78    275258\n",
      "\n",
      "Model:  xgb\n",
      "  accuracy_score =  0.9922945018855038\n",
      "  recall_score =  0.7672856714957524\n",
      "  precision_score =  0.7244137549510503\n",
      "  f1_score =  0.7355250278395755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classification_report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23824\n",
      "           1       1.00      1.00      1.00     23890\n",
      "           2       1.00      1.00      1.00     24172\n",
      "           3       1.00      1.00      1.00     31749\n",
      "           4       1.00      1.00      1.00     26523\n",
      "           5       1.00      1.00      1.00     42340\n",
      "           6       1.00      1.00      1.00     21422\n",
      "           7       1.00      1.00      1.00      1635\n",
      "           8       1.00      1.00      1.00      1689\n",
      "           9       1.00      1.00      1.00      2676\n",
      "          10       0.98      0.97      0.98       133\n",
      "          11       0.98      0.97      0.97       148\n",
      "          12       1.00      1.00      1.00     19592\n",
      "          13       1.00      1.00      1.00     12010\n",
      "          14       1.00      1.00      1.00     15932\n",
      "          15       0.99      1.00      0.99       450\n",
      "          16       1.00      1.00      1.00      5683\n",
      "          17       1.00      0.99      1.00      4523\n",
      "          18       1.00      1.00      1.00      5247\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.34      0.55      0.42       351\n",
      "          21       0.54      0.59      0.57       443\n",
      "          22       0.98      0.97      0.97       208\n",
      "          23       0.78      0.74      0.76       857\n",
      "          24       0.66      0.71      0.68       990\n",
      "          25       0.80      0.85      0.82      1736\n",
      "          26       0.96      0.88      0.92      6964\n",
      "          27       0.03      0.25      0.05         4\n",
      "          28       0.00      0.00      0.00         5\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.10      0.20      0.14        15\n",
      "          32       0.24      0.67      0.35         9\n",
      "          33       0.27      0.76      0.40        33\n",
      "\n",
      "    accuracy                           0.99    275258\n",
      "   macro avg       0.72      0.77      0.74    275258\n",
      "weighted avg       0.99      0.99      0.99    275258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for model in tqdm(best_estimators):\n",
    "    y_pred = list(best_estimators[model].predict(X_test))\n",
    "\n",
    "    # Evaluate\n",
    "    y_test = list(y_test)\n",
    "    f1score = f1_score(y_pred, y_test, average='macro')\n",
    "    print('Model: ', model)\n",
    "    print('  accuracy_score = ', accuracy_score(y_pred, y_test))\n",
    "    print('  recall_score = ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('  precision_score = ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('  f1_score = ', f1score)\n",
    "    print('  classification_report = \\n', classification_report(y_pred, y_test))\n",
    "\n",
    "    if f1score > best_score:\n",
    "        best_score = f1score\n",
    "        best_model = best_estimators[model]\n",
    "\n",
    "dump(best_model, './outputs/best_model_all_attacks.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
